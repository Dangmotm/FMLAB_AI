{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259d2fe9-8df1-4277-a223-9ed3689beb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b7b08d3-6e66-4b50-90ff-dd7efc158b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "display_step = 100\n",
    "checkpoint = 'Dang.pth'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "assert device == 'cuda'\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6490ed2-32ad-48ec-a409-2db8bfd0cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train = True, download = True, transform = transform)\n",
    "test_dataset = datasets.MNIST('../data', train = False, transform = transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00327a99-86ca-48d3-82fe-4d31a11112e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, padding = 0)\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding = 0)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.maxpool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7719951-331a-40a6-ac4f-714551a37bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! Hãy train để có checkpoint file\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(checkpoint))\n",
    "except:\n",
    "    print(\"!!! Hãy train để có checkpoint file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebea3fd0-bbeb-40e7-a412-1721348f7346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 [0/60000 (0%)]\tTrain Loss: 2.304181\n",
      "Train epoch: 1 [6400/60000 (11%)]\tTrain Loss: 0.401362\n",
      "Train epoch: 1 [12800/60000 (21%)]\tTrain Loss: 0.277918\n",
      "Train epoch: 1 [19200/60000 (32%)]\tTrain Loss: 0.196355\n",
      "Train epoch: 1 [25600/60000 (43%)]\tTrain Loss: 0.194131\n",
      "Train epoch: 1 [32000/60000 (53%)]\tTrain Loss: 0.065960\n",
      "Train epoch: 1 [38400/60000 (64%)]\tTrain Loss: 0.246756\n",
      "Train epoch: 1 [44800/60000 (75%)]\tTrain Loss: 0.180514\n",
      "Train epoch: 1 [51200/60000 (85%)]\tTrain Loss: 0.409834\n",
      "Train epoch: 1 [57600/60000 (96%)]\tTrain Loss: 0.145121\n",
      "***********    TEST_ACC = 9680%    ***********\n",
      "Train epoch: 2 [0/60000 (0%)]\tTrain Loss: 0.047759\n",
      "Train epoch: 2 [6400/60000 (11%)]\tTrain Loss: 0.164887\n",
      "Train epoch: 2 [12800/60000 (21%)]\tTrain Loss: 0.076887\n",
      "Train epoch: 2 [19200/60000 (32%)]\tTrain Loss: 0.147850\n",
      "Train epoch: 2 [25600/60000 (43%)]\tTrain Loss: 0.045038\n",
      "Train epoch: 2 [32000/60000 (53%)]\tTrain Loss: 0.052051\n",
      "Train epoch: 2 [38400/60000 (64%)]\tTrain Loss: 0.072176\n",
      "Train epoch: 2 [44800/60000 (75%)]\tTrain Loss: 0.047136\n",
      "Train epoch: 2 [51200/60000 (85%)]\tTrain Loss: 0.143827\n",
      "Train epoch: 2 [57600/60000 (96%)]\tTrain Loss: 0.046732\n",
      "***********    TEST_ACC = 9822%    ***********\n",
      "Train epoch: 3 [0/60000 (0%)]\tTrain Loss: 0.005201\n",
      "Train epoch: 3 [6400/60000 (11%)]\tTrain Loss: 0.115037\n",
      "Train epoch: 3 [12800/60000 (21%)]\tTrain Loss: 0.078974\n",
      "Train epoch: 3 [19200/60000 (32%)]\tTrain Loss: 0.123981\n",
      "Train epoch: 3 [25600/60000 (43%)]\tTrain Loss: 0.139097\n",
      "Train epoch: 3 [32000/60000 (53%)]\tTrain Loss: 0.055538\n",
      "Train epoch: 3 [38400/60000 (64%)]\tTrain Loss: 0.053347\n",
      "Train epoch: 3 [44800/60000 (75%)]\tTrain Loss: 0.068875\n",
      "Train epoch: 3 [51200/60000 (85%)]\tTrain Loss: 0.183597\n",
      "Train epoch: 3 [57600/60000 (96%)]\tTrain Loss: 0.028564\n",
      "***********    TEST_ACC = 9825%    ***********\n",
      "Train epoch: 4 [0/60000 (0%)]\tTrain Loss: 0.006581\n",
      "Train epoch: 4 [6400/60000 (11%)]\tTrain Loss: 0.102387\n",
      "Train epoch: 4 [12800/60000 (21%)]\tTrain Loss: 0.090683\n",
      "Train epoch: 4 [19200/60000 (32%)]\tTrain Loss: 0.033561\n",
      "Train epoch: 4 [25600/60000 (43%)]\tTrain Loss: 0.018367\n",
      "Train epoch: 4 [32000/60000 (53%)]\tTrain Loss: 0.067816\n",
      "Train epoch: 4 [38400/60000 (64%)]\tTrain Loss: 0.050356\n",
      "Train epoch: 4 [44800/60000 (75%)]\tTrain Loss: 0.004267\n",
      "Train epoch: 4 [51200/60000 (85%)]\tTrain Loss: 0.089169\n",
      "Train epoch: 4 [57600/60000 (96%)]\tTrain Loss: 0.026311\n",
      "***********    TEST_ACC = 9845%    ***********\n",
      "Train epoch: 5 [0/60000 (0%)]\tTrain Loss: 0.007780\n",
      "Train epoch: 5 [6400/60000 (11%)]\tTrain Loss: 0.163534\n",
      "Train epoch: 5 [12800/60000 (21%)]\tTrain Loss: 0.141028\n",
      "Train epoch: 5 [19200/60000 (32%)]\tTrain Loss: 0.092806\n",
      "Train epoch: 5 [25600/60000 (43%)]\tTrain Loss: 0.051652\n",
      "Train epoch: 5 [32000/60000 (53%)]\tTrain Loss: 0.010025\n",
      "Train epoch: 5 [38400/60000 (64%)]\tTrain Loss: 0.060408\n",
      "Train epoch: 5 [44800/60000 (75%)]\tTrain Loss: 0.021397\n",
      "Train epoch: 5 [51200/60000 (85%)]\tTrain Loss: 0.216361\n",
      "Train epoch: 5 [57600/60000 (96%)]\tTrain Loss: 0.046325\n",
      "***********    TEST_ACC = 9861%    ***********\n",
      "Train epoch: 6 [0/60000 (0%)]\tTrain Loss: 0.000775\n",
      "Train epoch: 6 [6400/60000 (11%)]\tTrain Loss: 0.228649\n",
      "Train epoch: 6 [12800/60000 (21%)]\tTrain Loss: 0.125637\n",
      "Train epoch: 6 [19200/60000 (32%)]\tTrain Loss: 0.003223\n",
      "Train epoch: 6 [25600/60000 (43%)]\tTrain Loss: 0.011493\n",
      "Train epoch: 6 [32000/60000 (53%)]\tTrain Loss: 0.008409\n",
      "Train epoch: 6 [38400/60000 (64%)]\tTrain Loss: 0.019935\n",
      "Train epoch: 6 [44800/60000 (75%)]\tTrain Loss: 0.016491\n",
      "Train epoch: 6 [51200/60000 (85%)]\tTrain Loss: 0.120818\n",
      "Train epoch: 6 [57600/60000 (96%)]\tTrain Loss: 0.048504\n",
      "Train epoch: 7 [0/60000 (0%)]\tTrain Loss: 0.001595\n",
      "Train epoch: 7 [6400/60000 (11%)]\tTrain Loss: 0.023643\n",
      "Train epoch: 7 [12800/60000 (21%)]\tTrain Loss: 0.050920\n",
      "Train epoch: 7 [19200/60000 (32%)]\tTrain Loss: 0.142486\n",
      "Train epoch: 7 [25600/60000 (43%)]\tTrain Loss: 0.004020\n",
      "Train epoch: 7 [32000/60000 (53%)]\tTrain Loss: 0.001183\n",
      "Train epoch: 7 [38400/60000 (64%)]\tTrain Loss: 0.023521\n",
      "Train epoch: 7 [44800/60000 (75%)]\tTrain Loss: 0.017974\n",
      "Train epoch: 7 [51200/60000 (85%)]\tTrain Loss: 0.087304\n",
      "Train epoch: 7 [57600/60000 (96%)]\tTrain Loss: 0.016936\n",
      "Train epoch: 8 [0/60000 (0%)]\tTrain Loss: 0.004479\n",
      "Train epoch: 8 [6400/60000 (11%)]\tTrain Loss: 0.149643\n",
      "Train epoch: 8 [12800/60000 (21%)]\tTrain Loss: 0.013337\n",
      "Train epoch: 8 [19200/60000 (32%)]\tTrain Loss: 0.247087\n",
      "Train epoch: 8 [25600/60000 (43%)]\tTrain Loss: 0.011294\n",
      "Train epoch: 8 [32000/60000 (53%)]\tTrain Loss: 0.066895\n",
      "Train epoch: 8 [38400/60000 (64%)]\tTrain Loss: 0.020136\n",
      "Train epoch: 8 [44800/60000 (75%)]\tTrain Loss: 0.003567\n",
      "Train epoch: 8 [51200/60000 (85%)]\tTrain Loss: 0.097103\n",
      "Train epoch: 8 [57600/60000 (96%)]\tTrain Loss: 0.006483\n",
      "Train epoch: 9 [0/60000 (0%)]\tTrain Loss: 0.000727\n",
      "Train epoch: 9 [6400/60000 (11%)]\tTrain Loss: 0.010094\n",
      "Train epoch: 9 [12800/60000 (21%)]\tTrain Loss: 0.013954\n",
      "Train epoch: 9 [19200/60000 (32%)]\tTrain Loss: 0.056358\n",
      "Train epoch: 9 [25600/60000 (43%)]\tTrain Loss: 0.022138\n",
      "Train epoch: 9 [32000/60000 (53%)]\tTrain Loss: 0.001806\n",
      "Train epoch: 9 [38400/60000 (64%)]\tTrain Loss: 0.025274\n",
      "Train epoch: 9 [44800/60000 (75%)]\tTrain Loss: 0.018631\n",
      "Train epoch: 9 [51200/60000 (85%)]\tTrain Loss: 0.159516\n",
      "Train epoch: 9 [57600/60000 (96%)]\tTrain Loss: 0.061664\n",
      "Train epoch: 10 [0/60000 (0%)]\tTrain Loss: 0.001908\n",
      "Train epoch: 10 [6400/60000 (11%)]\tTrain Loss: 0.092468\n",
      "Train epoch: 10 [12800/60000 (21%)]\tTrain Loss: 0.052952\n",
      "Train epoch: 10 [19200/60000 (32%)]\tTrain Loss: 0.000516\n",
      "Train epoch: 10 [25600/60000 (43%)]\tTrain Loss: 0.002920\n",
      "Train epoch: 10 [32000/60000 (53%)]\tTrain Loss: 0.115850\n",
      "Train epoch: 10 [38400/60000 (64%)]\tTrain Loss: 0.009811\n",
      "Train epoch: 10 [44800/60000 (75%)]\tTrain Loss: 0.002287\n",
      "Train epoch: 10 [51200/60000 (85%)]\tTrain Loss: 0.139794\n",
      "Train epoch: 10 [57600/60000 (96%)]\tTrain Loss: 0.157679\n",
      "Train epoch: 11 [0/60000 (0%)]\tTrain Loss: 0.000816\n",
      "Train epoch: 11 [6400/60000 (11%)]\tTrain Loss: 0.091304\n",
      "Train epoch: 11 [12800/60000 (21%)]\tTrain Loss: 0.061641\n",
      "Train epoch: 11 [19200/60000 (32%)]\tTrain Loss: 0.001173\n",
      "Train epoch: 11 [25600/60000 (43%)]\tTrain Loss: 0.002914\n",
      "Train epoch: 11 [32000/60000 (53%)]\tTrain Loss: 0.008618\n",
      "Train epoch: 11 [38400/60000 (64%)]\tTrain Loss: 0.016874\n",
      "Train epoch: 11 [44800/60000 (75%)]\tTrain Loss: 0.003995\n",
      "Train epoch: 11 [51200/60000 (85%)]\tTrain Loss: 0.033835\n",
      "Train epoch: 11 [57600/60000 (96%)]\tTrain Loss: 0.000407\n",
      "Train epoch: 12 [0/60000 (0%)]\tTrain Loss: 0.006325\n",
      "Train epoch: 12 [6400/60000 (11%)]\tTrain Loss: 0.005626\n",
      "Train epoch: 12 [12800/60000 (21%)]\tTrain Loss: 0.037563\n",
      "Train epoch: 12 [19200/60000 (32%)]\tTrain Loss: 0.002571\n",
      "Train epoch: 12 [25600/60000 (43%)]\tTrain Loss: 0.067408\n",
      "Train epoch: 12 [32000/60000 (53%)]\tTrain Loss: 0.098522\n",
      "Train epoch: 12 [38400/60000 (64%)]\tTrain Loss: 0.011403\n",
      "Train epoch: 12 [44800/60000 (75%)]\tTrain Loss: 0.004957\n",
      "Train epoch: 12 [51200/60000 (85%)]\tTrain Loss: 0.000918\n",
      "Train epoch: 12 [57600/60000 (96%)]\tTrain Loss: 0.001163\n",
      "Train epoch: 13 [0/60000 (0%)]\tTrain Loss: 0.001490\n",
      "Train epoch: 13 [6400/60000 (11%)]\tTrain Loss: 0.035043\n",
      "Train epoch: 13 [12800/60000 (21%)]\tTrain Loss: 0.015186\n",
      "Train epoch: 13 [19200/60000 (32%)]\tTrain Loss: 0.007974\n",
      "Train epoch: 13 [25600/60000 (43%)]\tTrain Loss: 0.006337\n",
      "Train epoch: 13 [32000/60000 (53%)]\tTrain Loss: 0.060220\n",
      "Train epoch: 13 [38400/60000 (64%)]\tTrain Loss: 0.010196\n",
      "Train epoch: 13 [44800/60000 (75%)]\tTrain Loss: 0.005597\n",
      "Train epoch: 13 [51200/60000 (85%)]\tTrain Loss: 0.055893\n",
      "Train epoch: 13 [57600/60000 (96%)]\tTrain Loss: 0.035112\n",
      "Train epoch: 14 [0/60000 (0%)]\tTrain Loss: 0.000271\n",
      "Train epoch: 14 [6400/60000 (11%)]\tTrain Loss: 0.003827\n",
      "Train epoch: 14 [12800/60000 (21%)]\tTrain Loss: 0.036680\n",
      "Train epoch: 14 [19200/60000 (32%)]\tTrain Loss: 0.001366\n",
      "Train epoch: 14 [25600/60000 (43%)]\tTrain Loss: 0.003863\n",
      "Train epoch: 14 [32000/60000 (53%)]\tTrain Loss: 0.011340\n",
      "Train epoch: 14 [38400/60000 (64%)]\tTrain Loss: 0.003816\n",
      "Train epoch: 14 [44800/60000 (75%)]\tTrain Loss: 0.051333\n",
      "Train epoch: 14 [51200/60000 (85%)]\tTrain Loss: 0.099911\n",
      "Train epoch: 14 [57600/60000 (96%)]\tTrain Loss: 0.014554\n",
      "Train epoch: 15 [0/60000 (0%)]\tTrain Loss: 0.003137\n",
      "Train epoch: 15 [6400/60000 (11%)]\tTrain Loss: 0.005976\n",
      "Train epoch: 15 [12800/60000 (21%)]\tTrain Loss: 0.012191\n",
      "Train epoch: 15 [19200/60000 (32%)]\tTrain Loss: 0.003989\n",
      "Train epoch: 15 [25600/60000 (43%)]\tTrain Loss: 0.001142\n",
      "Train epoch: 15 [32000/60000 (53%)]\tTrain Loss: 0.003738\n",
      "Train epoch: 15 [38400/60000 (64%)]\tTrain Loss: 0.003043\n",
      "Train epoch: 15 [44800/60000 (75%)]\tTrain Loss: 0.001552\n",
      "Train epoch: 15 [51200/60000 (85%)]\tTrain Loss: 0.069923\n",
      "Train epoch: 15 [57600/60000 (96%)]\tTrain Loss: 0.001670\n",
      "Train epoch: 16 [0/60000 (0%)]\tTrain Loss: 0.000238\n",
      "Train epoch: 16 [6400/60000 (11%)]\tTrain Loss: 0.009333\n",
      "Train epoch: 16 [12800/60000 (21%)]\tTrain Loss: 0.015864\n",
      "Train epoch: 16 [19200/60000 (32%)]\tTrain Loss: 0.003509\n",
      "Train epoch: 16 [25600/60000 (43%)]\tTrain Loss: 0.000424\n",
      "Train epoch: 16 [32000/60000 (53%)]\tTrain Loss: 0.001957\n",
      "Train epoch: 16 [38400/60000 (64%)]\tTrain Loss: 0.019639\n",
      "Train epoch: 16 [44800/60000 (75%)]\tTrain Loss: 0.014009\n",
      "Train epoch: 16 [51200/60000 (85%)]\tTrain Loss: 0.005430\n",
      "Train epoch: 16 [57600/60000 (96%)]\tTrain Loss: 0.000594\n",
      "Train epoch: 17 [0/60000 (0%)]\tTrain Loss: 0.000149\n",
      "Train epoch: 17 [6400/60000 (11%)]\tTrain Loss: 0.028441\n",
      "Train epoch: 17 [12800/60000 (21%)]\tTrain Loss: 0.052073\n",
      "Train epoch: 17 [19200/60000 (32%)]\tTrain Loss: 0.002458\n",
      "Train epoch: 17 [25600/60000 (43%)]\tTrain Loss: 0.000972\n",
      "Train epoch: 17 [32000/60000 (53%)]\tTrain Loss: 0.000887\n",
      "Train epoch: 17 [38400/60000 (64%)]\tTrain Loss: 0.001993\n",
      "Train epoch: 17 [44800/60000 (75%)]\tTrain Loss: 0.002622\n",
      "Train epoch: 17 [51200/60000 (85%)]\tTrain Loss: 0.014908\n",
      "Train epoch: 17 [57600/60000 (96%)]\tTrain Loss: 0.001697\n",
      "Train epoch: 18 [0/60000 (0%)]\tTrain Loss: 0.008158\n",
      "Train epoch: 18 [6400/60000 (11%)]\tTrain Loss: 0.018035\n",
      "Train epoch: 18 [12800/60000 (21%)]\tTrain Loss: 0.000530\n",
      "Train epoch: 18 [19200/60000 (32%)]\tTrain Loss: 0.000374\n",
      "Train epoch: 18 [25600/60000 (43%)]\tTrain Loss: 0.001819\n",
      "Train epoch: 18 [32000/60000 (53%)]\tTrain Loss: 0.005993\n",
      "Train epoch: 18 [38400/60000 (64%)]\tTrain Loss: 0.002255\n",
      "Train epoch: 18 [44800/60000 (75%)]\tTrain Loss: 0.014390\n",
      "Train epoch: 18 [51200/60000 (85%)]\tTrain Loss: 0.000105\n",
      "Train epoch: 18 [57600/60000 (96%)]\tTrain Loss: 0.000156\n",
      "Train epoch: 19 [0/60000 (0%)]\tTrain Loss: 0.002010\n",
      "Train epoch: 19 [6400/60000 (11%)]\tTrain Loss: 0.005468\n",
      "Train epoch: 19 [12800/60000 (21%)]\tTrain Loss: 0.093439\n",
      "Train epoch: 19 [19200/60000 (32%)]\tTrain Loss: 0.000716\n",
      "Train epoch: 19 [25600/60000 (43%)]\tTrain Loss: 0.000779\n",
      "Train epoch: 19 [32000/60000 (53%)]\tTrain Loss: 0.002254\n",
      "Train epoch: 19 [38400/60000 (64%)]\tTrain Loss: 0.007239\n",
      "Train epoch: 19 [44800/60000 (75%)]\tTrain Loss: 0.001521\n",
      "Train epoch: 19 [51200/60000 (85%)]\tTrain Loss: 0.065527\n",
      "Train epoch: 19 [57600/60000 (96%)]\tTrain Loss: 0.004266\n",
      "Train epoch: 20 [0/60000 (0%)]\tTrain Loss: 0.000101\n",
      "Train epoch: 20 [6400/60000 (11%)]\tTrain Loss: 0.000265\n",
      "Train epoch: 20 [12800/60000 (21%)]\tTrain Loss: 0.001765\n",
      "Train epoch: 20 [19200/60000 (32%)]\tTrain Loss: 0.165174\n",
      "Train epoch: 20 [25600/60000 (43%)]\tTrain Loss: 0.111965\n",
      "Train epoch: 20 [32000/60000 (53%)]\tTrain Loss: 0.000719\n",
      "Train epoch: 20 [38400/60000 (64%)]\tTrain Loss: 0.000828\n",
      "Train epoch: 20 [44800/60000 (75%)]\tTrain Loss: 0.000380\n",
      "Train epoch: 20 [51200/60000 (85%)]\tTrain Loss: 0.096068\n",
      "Train epoch: 20 [57600/60000 (96%)]\tTrain Loss: 0.030028\n",
      "Train epoch: 21 [0/60000 (0%)]\tTrain Loss: 0.000095\n",
      "Train epoch: 21 [6400/60000 (11%)]\tTrain Loss: 0.003326\n",
      "Train epoch: 21 [12800/60000 (21%)]\tTrain Loss: 0.009846\n",
      "Train epoch: 21 [19200/60000 (32%)]\tTrain Loss: 0.031937\n",
      "Train epoch: 21 [25600/60000 (43%)]\tTrain Loss: 0.000174\n",
      "Train epoch: 21 [32000/60000 (53%)]\tTrain Loss: 0.035127\n",
      "Train epoch: 21 [38400/60000 (64%)]\tTrain Loss: 0.000569\n",
      "Train epoch: 21 [44800/60000 (75%)]\tTrain Loss: 0.003168\n",
      "Train epoch: 21 [51200/60000 (85%)]\tTrain Loss: 0.000323\n",
      "Train epoch: 21 [57600/60000 (96%)]\tTrain Loss: 0.018713\n",
      "Train epoch: 22 [0/60000 (0%)]\tTrain Loss: 0.000130\n",
      "Train epoch: 22 [6400/60000 (11%)]\tTrain Loss: 0.008907\n",
      "Train epoch: 22 [12800/60000 (21%)]\tTrain Loss: 0.088492\n",
      "Train epoch: 22 [19200/60000 (32%)]\tTrain Loss: 0.004187\n",
      "Train epoch: 22 [25600/60000 (43%)]\tTrain Loss: 0.000511\n",
      "Train epoch: 22 [32000/60000 (53%)]\tTrain Loss: 0.000286\n",
      "Train epoch: 22 [38400/60000 (64%)]\tTrain Loss: 0.023904\n",
      "Train epoch: 22 [44800/60000 (75%)]\tTrain Loss: 0.025428\n",
      "Train epoch: 22 [51200/60000 (85%)]\tTrain Loss: 0.003061\n",
      "Train epoch: 22 [57600/60000 (96%)]\tTrain Loss: 0.000075\n",
      "Train epoch: 23 [0/60000 (0%)]\tTrain Loss: 0.000025\n",
      "Train epoch: 23 [6400/60000 (11%)]\tTrain Loss: 0.000430\n",
      "Train epoch: 23 [12800/60000 (21%)]\tTrain Loss: 0.003634\n",
      "Train epoch: 23 [19200/60000 (32%)]\tTrain Loss: 0.000430\n",
      "Train epoch: 23 [25600/60000 (43%)]\tTrain Loss: 0.000198\n",
      "Train epoch: 23 [32000/60000 (53%)]\tTrain Loss: 0.019111\n",
      "Train epoch: 23 [38400/60000 (64%)]\tTrain Loss: 0.221146\n",
      "Train epoch: 23 [44800/60000 (75%)]\tTrain Loss: 0.000016\n",
      "Train epoch: 23 [51200/60000 (85%)]\tTrain Loss: 0.037437\n",
      "Train epoch: 23 [57600/60000 (96%)]\tTrain Loss: 0.000004\n",
      "Train epoch: 24 [0/60000 (0%)]\tTrain Loss: 0.000079\n",
      "Train epoch: 24 [6400/60000 (11%)]\tTrain Loss: 0.000304\n",
      "Train epoch: 24 [12800/60000 (21%)]\tTrain Loss: 0.073354\n",
      "Train epoch: 24 [19200/60000 (32%)]\tTrain Loss: 0.001250\n",
      "Train epoch: 24 [25600/60000 (43%)]\tTrain Loss: 0.015823\n",
      "Train epoch: 24 [32000/60000 (53%)]\tTrain Loss: 0.003433\n",
      "Train epoch: 24 [38400/60000 (64%)]\tTrain Loss: 0.015758\n",
      "Train epoch: 24 [44800/60000 (75%)]\tTrain Loss: 0.000385\n",
      "Train epoch: 24 [51200/60000 (85%)]\tTrain Loss: 0.024545\n",
      "Train epoch: 24 [57600/60000 (96%)]\tTrain Loss: 0.035761\n",
      "Train epoch: 25 [0/60000 (0%)]\tTrain Loss: 0.000144\n",
      "Train epoch: 25 [6400/60000 (11%)]\tTrain Loss: 0.000902\n",
      "Train epoch: 25 [12800/60000 (21%)]\tTrain Loss: 0.001349\n",
      "Train epoch: 25 [19200/60000 (32%)]\tTrain Loss: 0.000155\n",
      "Train epoch: 25 [25600/60000 (43%)]\tTrain Loss: 0.000840\n",
      "Train epoch: 25 [32000/60000 (53%)]\tTrain Loss: 0.127862\n",
      "Train epoch: 25 [38400/60000 (64%)]\tTrain Loss: 0.002984\n",
      "Train epoch: 25 [44800/60000 (75%)]\tTrain Loss: 0.037032\n",
      "Train epoch: 25 [51200/60000 (85%)]\tTrain Loss: 0.009349\n",
      "Train epoch: 25 [57600/60000 (96%)]\tTrain Loss: 0.000096\n",
      "Train epoch: 26 [0/60000 (0%)]\tTrain Loss: 0.000380\n",
      "Train epoch: 26 [6400/60000 (11%)]\tTrain Loss: 0.000058\n",
      "Train epoch: 26 [12800/60000 (21%)]\tTrain Loss: 0.037880\n",
      "Train epoch: 26 [19200/60000 (32%)]\tTrain Loss: 0.012878\n",
      "Train epoch: 26 [25600/60000 (43%)]\tTrain Loss: 0.000486\n",
      "Train epoch: 26 [32000/60000 (53%)]\tTrain Loss: 0.000159\n",
      "Train epoch: 26 [38400/60000 (64%)]\tTrain Loss: 0.007485\n",
      "Train epoch: 26 [44800/60000 (75%)]\tTrain Loss: 0.010586\n",
      "Train epoch: 26 [51200/60000 (85%)]\tTrain Loss: 0.000853\n",
      "Train epoch: 26 [57600/60000 (96%)]\tTrain Loss: 0.001365\n",
      "Train epoch: 27 [0/60000 (0%)]\tTrain Loss: 0.000002\n",
      "Train epoch: 27 [6400/60000 (11%)]\tTrain Loss: 0.000456\n",
      "Train epoch: 27 [12800/60000 (21%)]\tTrain Loss: 0.001305\n",
      "Train epoch: 27 [19200/60000 (32%)]\tTrain Loss: 0.000126\n",
      "Train epoch: 27 [25600/60000 (43%)]\tTrain Loss: 0.000568\n",
      "Train epoch: 27 [32000/60000 (53%)]\tTrain Loss: 0.001607\n",
      "Train epoch: 27 [38400/60000 (64%)]\tTrain Loss: 0.031212\n",
      "Train epoch: 27 [44800/60000 (75%)]\tTrain Loss: 0.003744\n",
      "Train epoch: 27 [51200/60000 (85%)]\tTrain Loss: 0.077583\n",
      "Train epoch: 27 [57600/60000 (96%)]\tTrain Loss: 0.014667\n",
      "Train epoch: 28 [0/60000 (0%)]\tTrain Loss: 0.000068\n",
      "Train epoch: 28 [6400/60000 (11%)]\tTrain Loss: 0.000002\n",
      "Train epoch: 28 [12800/60000 (21%)]\tTrain Loss: 0.000371\n",
      "Train epoch: 28 [19200/60000 (32%)]\tTrain Loss: 0.000005\n",
      "Train epoch: 28 [25600/60000 (43%)]\tTrain Loss: 0.000657\n",
      "Train epoch: 28 [32000/60000 (53%)]\tTrain Loss: 0.025161\n",
      "Train epoch: 28 [38400/60000 (64%)]\tTrain Loss: 0.011970\n",
      "Train epoch: 28 [44800/60000 (75%)]\tTrain Loss: 0.000199\n",
      "Train epoch: 28 [51200/60000 (85%)]\tTrain Loss: 0.000101\n",
      "Train epoch: 28 [57600/60000 (96%)]\tTrain Loss: 0.017159\n",
      "Train epoch: 29 [0/60000 (0%)]\tTrain Loss: 0.000433\n",
      "Train epoch: 29 [6400/60000 (11%)]\tTrain Loss: 0.000143\n",
      "Train epoch: 29 [12800/60000 (21%)]\tTrain Loss: 0.020905\n",
      "Train epoch: 29 [19200/60000 (32%)]\tTrain Loss: 0.000538\n",
      "Train epoch: 29 [25600/60000 (43%)]\tTrain Loss: 0.000005\n",
      "Train epoch: 29 [32000/60000 (53%)]\tTrain Loss: 0.000088\n",
      "Train epoch: 29 [38400/60000 (64%)]\tTrain Loss: 0.005576\n",
      "Train epoch: 29 [44800/60000 (75%)]\tTrain Loss: 0.000122\n",
      "Train epoch: 29 [51200/60000 (85%)]\tTrain Loss: 0.000050\n",
      "Train epoch: 29 [57600/60000 (96%)]\tTrain Loss: 0.000002\n",
      "Train epoch: 30 [0/60000 (0%)]\tTrain Loss: 0.000000\n",
      "Train epoch: 30 [6400/60000 (11%)]\tTrain Loss: 0.006510\n",
      "Train epoch: 30 [12800/60000 (21%)]\tTrain Loss: 0.006940\n",
      "Train epoch: 30 [19200/60000 (32%)]\tTrain Loss: 0.000268\n",
      "Train epoch: 30 [25600/60000 (43%)]\tTrain Loss: 0.000019\n",
      "Train epoch: 30 [32000/60000 (53%)]\tTrain Loss: 0.000292\n",
      "Train epoch: 30 [38400/60000 (64%)]\tTrain Loss: 0.000063\n",
      "Train epoch: 30 [44800/60000 (75%)]\tTrain Loss: 0.019369\n",
      "Train epoch: 30 [51200/60000 (85%)]\tTrain Loss: 0.000059\n",
      "Train epoch: 30 [57600/60000 (96%)]\tTrain Loss: 0.039161\n",
      "Train epoch: 31 [0/60000 (0%)]\tTrain Loss: 0.000045\n",
      "Train epoch: 31 [6400/60000 (11%)]\tTrain Loss: 0.000697\n",
      "Train epoch: 31 [12800/60000 (21%)]\tTrain Loss: 0.001541\n",
      "Train epoch: 31 [19200/60000 (32%)]\tTrain Loss: 0.000745\n",
      "Train epoch: 31 [25600/60000 (43%)]\tTrain Loss: 0.000072\n",
      "Train epoch: 31 [32000/60000 (53%)]\tTrain Loss: 0.000005\n",
      "Train epoch: 31 [38400/60000 (64%)]\tTrain Loss: 0.002346\n",
      "Train epoch: 31 [44800/60000 (75%)]\tTrain Loss: 0.000025\n",
      "Train epoch: 31 [51200/60000 (85%)]\tTrain Loss: 0.104977\n",
      "Train epoch: 31 [57600/60000 (96%)]\tTrain Loss: 0.000110\n",
      "Train epoch: 32 [0/60000 (0%)]\tTrain Loss: 0.018041\n",
      "Train epoch: 32 [6400/60000 (11%)]\tTrain Loss: 0.000854\n",
      "Train epoch: 32 [12800/60000 (21%)]\tTrain Loss: 0.001554\n",
      "Train epoch: 32 [19200/60000 (32%)]\tTrain Loss: 0.000412\n",
      "Train epoch: 32 [25600/60000 (43%)]\tTrain Loss: 0.003031\n",
      "Train epoch: 32 [32000/60000 (53%)]\tTrain Loss: 0.004253\n",
      "Train epoch: 32 [38400/60000 (64%)]\tTrain Loss: 0.001448\n",
      "Train epoch: 32 [44800/60000 (75%)]\tTrain Loss: 0.008892\n",
      "Train epoch: 32 [51200/60000 (85%)]\tTrain Loss: 0.005216\n",
      "Train epoch: 32 [57600/60000 (96%)]\tTrain Loss: 0.000088\n",
      "Train epoch: 33 [0/60000 (0%)]\tTrain Loss: 0.000352\n",
      "Train epoch: 33 [6400/60000 (11%)]\tTrain Loss: 0.000034\n",
      "Train epoch: 33 [12800/60000 (21%)]\tTrain Loss: 0.000091\n",
      "Train epoch: 33 [19200/60000 (32%)]\tTrain Loss: 0.005133\n",
      "Train epoch: 33 [25600/60000 (43%)]\tTrain Loss: 0.000034\n",
      "Train epoch: 33 [32000/60000 (53%)]\tTrain Loss: 0.005153\n",
      "Train epoch: 33 [38400/60000 (64%)]\tTrain Loss: 0.039961\n",
      "Train epoch: 33 [44800/60000 (75%)]\tTrain Loss: 0.000051\n",
      "Train epoch: 33 [51200/60000 (85%)]\tTrain Loss: 0.003830\n",
      "Train epoch: 33 [57600/60000 (96%)]\tTrain Loss: 0.000005\n",
      "Train epoch: 34 [0/60000 (0%)]\tTrain Loss: 0.000014\n",
      "Train epoch: 34 [6400/60000 (11%)]\tTrain Loss: 0.006596\n",
      "Train epoch: 34 [12800/60000 (21%)]\tTrain Loss: 0.000406\n",
      "Train epoch: 34 [19200/60000 (32%)]\tTrain Loss: 0.000928\n",
      "Train epoch: 34 [25600/60000 (43%)]\tTrain Loss: 0.000208\n",
      "Train epoch: 34 [32000/60000 (53%)]\tTrain Loss: 0.000308\n",
      "Train epoch: 34 [38400/60000 (64%)]\tTrain Loss: 0.000007\n",
      "Train epoch: 34 [44800/60000 (75%)]\tTrain Loss: 0.000796\n",
      "Train epoch: 34 [51200/60000 (85%)]\tTrain Loss: 0.000082\n",
      "Train epoch: 34 [57600/60000 (96%)]\tTrain Loss: 0.000063\n",
      "Train epoch: 35 [0/60000 (0%)]\tTrain Loss: 0.000018\n",
      "Train epoch: 35 [6400/60000 (11%)]\tTrain Loss: 0.000013\n",
      "Train epoch: 35 [12800/60000 (21%)]\tTrain Loss: 0.039532\n",
      "Train epoch: 35 [19200/60000 (32%)]\tTrain Loss: 0.002166\n",
      "Train epoch: 35 [25600/60000 (43%)]\tTrain Loss: 0.000112\n",
      "Train epoch: 35 [32000/60000 (53%)]\tTrain Loss: 0.000003\n",
      "Train epoch: 35 [38400/60000 (64%)]\tTrain Loss: 0.001724\n",
      "Train epoch: 35 [44800/60000 (75%)]\tTrain Loss: 0.003625\n",
      "Train epoch: 35 [51200/60000 (85%)]\tTrain Loss: 0.001296\n",
      "Train epoch: 35 [57600/60000 (96%)]\tTrain Loss: 0.000039\n",
      "Train epoch: 36 [0/60000 (0%)]\tTrain Loss: 0.001204\n",
      "Train epoch: 36 [6400/60000 (11%)]\tTrain Loss: 0.000018\n",
      "Train epoch: 36 [12800/60000 (21%)]\tTrain Loss: 0.080454\n",
      "Train epoch: 36 [19200/60000 (32%)]\tTrain Loss: 0.000155\n",
      "Train epoch: 36 [25600/60000 (43%)]\tTrain Loss: 0.000381\n",
      "Train epoch: 36 [32000/60000 (53%)]\tTrain Loss: 0.000338\n",
      "Train epoch: 36 [38400/60000 (64%)]\tTrain Loss: 0.000166\n",
      "Train epoch: 36 [44800/60000 (75%)]\tTrain Loss: 0.033419\n",
      "Train epoch: 36 [51200/60000 (85%)]\tTrain Loss: 0.005964\n",
      "Train epoch: 36 [57600/60000 (96%)]\tTrain Loss: 0.000361\n",
      "Train epoch: 37 [0/60000 (0%)]\tTrain Loss: 0.002190\n",
      "Train epoch: 37 [6400/60000 (11%)]\tTrain Loss: 0.017733\n",
      "Train epoch: 37 [12800/60000 (21%)]\tTrain Loss: 0.000024\n",
      "Train epoch: 37 [19200/60000 (32%)]\tTrain Loss: 0.050398\n",
      "Train epoch: 37 [25600/60000 (43%)]\tTrain Loss: 0.000000\n",
      "Train epoch: 37 [32000/60000 (53%)]\tTrain Loss: 0.000147\n",
      "Train epoch: 37 [38400/60000 (64%)]\tTrain Loss: 0.000538\n",
      "Train epoch: 37 [44800/60000 (75%)]\tTrain Loss: 0.000213\n",
      "Train epoch: 37 [51200/60000 (85%)]\tTrain Loss: 0.000013\n",
      "Train epoch: 37 [57600/60000 (96%)]\tTrain Loss: 0.000069\n",
      "Train epoch: 38 [0/60000 (0%)]\tTrain Loss: 0.000005\n",
      "Train epoch: 38 [6400/60000 (11%)]\tTrain Loss: 0.000000\n",
      "Train epoch: 38 [12800/60000 (21%)]\tTrain Loss: 0.000427\n",
      "Train epoch: 38 [19200/60000 (32%)]\tTrain Loss: 0.095541\n",
      "Train epoch: 38 [25600/60000 (43%)]\tTrain Loss: 0.000063\n",
      "Train epoch: 38 [32000/60000 (53%)]\tTrain Loss: 0.000070\n",
      "Train epoch: 38 [38400/60000 (64%)]\tTrain Loss: 0.000003\n",
      "Train epoch: 38 [44800/60000 (75%)]\tTrain Loss: 0.000370\n",
      "Train epoch: 38 [51200/60000 (85%)]\tTrain Loss: 0.001496\n",
      "Train epoch: 38 [57600/60000 (96%)]\tTrain Loss: 0.000002\n",
      "Train epoch: 39 [0/60000 (0%)]\tTrain Loss: 0.000002\n",
      "Train epoch: 39 [6400/60000 (11%)]\tTrain Loss: 0.000003\n",
      "Train epoch: 39 [12800/60000 (21%)]\tTrain Loss: 0.001677\n",
      "Train epoch: 39 [19200/60000 (32%)]\tTrain Loss: 0.000001\n",
      "Train epoch: 39 [25600/60000 (43%)]\tTrain Loss: 0.000211\n",
      "Train epoch: 39 [32000/60000 (53%)]\tTrain Loss: 0.012251\n",
      "Train epoch: 39 [38400/60000 (64%)]\tTrain Loss: 0.000010\n",
      "Train epoch: 39 [44800/60000 (75%)]\tTrain Loss: 0.059503\n",
      "Train epoch: 39 [51200/60000 (85%)]\tTrain Loss: 0.131126\n",
      "Train epoch: 39 [57600/60000 (96%)]\tTrain Loss: 0.001631\n",
      "Train epoch: 40 [0/60000 (0%)]\tTrain Loss: 0.000078\n",
      "Train epoch: 40 [6400/60000 (11%)]\tTrain Loss: 0.001031\n",
      "Train epoch: 40 [12800/60000 (21%)]\tTrain Loss: 0.000640\n",
      "Train epoch: 40 [19200/60000 (32%)]\tTrain Loss: 0.002161\n",
      "Train epoch: 40 [25600/60000 (43%)]\tTrain Loss: 0.000022\n",
      "Train epoch: 40 [32000/60000 (53%)]\tTrain Loss: 0.000082\n",
      "Train epoch: 40 [38400/60000 (64%)]\tTrain Loss: 0.000743\n",
      "Train epoch: 40 [44800/60000 (75%)]\tTrain Loss: 0.002658\n",
      "Train epoch: 40 [51200/60000 (85%)]\tTrain Loss: 0.000012\n",
      "Train epoch: 40 [57600/60000 (96%)]\tTrain Loss: 0.000027\n",
      "Train epoch: 41 [0/60000 (0%)]\tTrain Loss: 0.001267\n",
      "Train epoch: 41 [6400/60000 (11%)]\tTrain Loss: 0.000015\n",
      "Train epoch: 41 [12800/60000 (21%)]\tTrain Loss: 0.002077\n",
      "Train epoch: 41 [19200/60000 (32%)]\tTrain Loss: 0.006960\n",
      "Train epoch: 41 [25600/60000 (43%)]\tTrain Loss: 0.000019\n",
      "Train epoch: 41 [32000/60000 (53%)]\tTrain Loss: 0.000496\n",
      "Train epoch: 41 [38400/60000 (64%)]\tTrain Loss: 0.000544\n",
      "Train epoch: 41 [44800/60000 (75%)]\tTrain Loss: 0.000000\n",
      "Train epoch: 41 [51200/60000 (85%)]\tTrain Loss: 0.127994\n",
      "Train epoch: 41 [57600/60000 (96%)]\tTrain Loss: 0.000323\n",
      "Train epoch: 42 [0/60000 (0%)]\tTrain Loss: 0.039709\n",
      "Train epoch: 42 [6400/60000 (11%)]\tTrain Loss: 0.000001\n",
      "Train epoch: 42 [12800/60000 (21%)]\tTrain Loss: 0.014015\n",
      "Train epoch: 42 [19200/60000 (32%)]\tTrain Loss: 0.000012\n",
      "Train epoch: 42 [25600/60000 (43%)]\tTrain Loss: 0.000718\n",
      "Train epoch: 42 [32000/60000 (53%)]\tTrain Loss: 0.000407\n",
      "Train epoch: 42 [38400/60000 (64%)]\tTrain Loss: 0.000015\n",
      "Train epoch: 42 [44800/60000 (75%)]\tTrain Loss: 0.002688\n",
      "Train epoch: 42 [51200/60000 (85%)]\tTrain Loss: 0.000657\n",
      "Train epoch: 42 [57600/60000 (96%)]\tTrain Loss: 0.000152\n",
      "Train epoch: 43 [0/60000 (0%)]\tTrain Loss: 0.000006\n",
      "Train epoch: 43 [6400/60000 (11%)]\tTrain Loss: 0.000132\n",
      "Train epoch: 43 [12800/60000 (21%)]\tTrain Loss: 0.004097\n",
      "Train epoch: 43 [19200/60000 (32%)]\tTrain Loss: 0.000004\n",
      "Train epoch: 43 [25600/60000 (43%)]\tTrain Loss: 0.000772\n",
      "Train epoch: 43 [32000/60000 (53%)]\tTrain Loss: 0.005193\n",
      "Train epoch: 43 [38400/60000 (64%)]\tTrain Loss: 0.000001\n",
      "Train epoch: 43 [44800/60000 (75%)]\tTrain Loss: 0.000039\n",
      "Train epoch: 43 [51200/60000 (85%)]\tTrain Loss: 0.002611\n",
      "Train epoch: 43 [57600/60000 (96%)]\tTrain Loss: 0.000796\n",
      "Train epoch: 44 [0/60000 (0%)]\tTrain Loss: 0.000001\n",
      "Train epoch: 44 [6400/60000 (11%)]\tTrain Loss: 0.041841\n",
      "Train epoch: 44 [12800/60000 (21%)]\tTrain Loss: 0.102979\n",
      "Train epoch: 44 [19200/60000 (32%)]\tTrain Loss: 0.000002\n",
      "Train epoch: 44 [25600/60000 (43%)]\tTrain Loss: 0.000001\n",
      "Train epoch: 44 [32000/60000 (53%)]\tTrain Loss: 0.000006\n",
      "Train epoch: 44 [38400/60000 (64%)]\tTrain Loss: 0.001642\n",
      "Train epoch: 44 [44800/60000 (75%)]\tTrain Loss: 0.000078\n",
      "Train epoch: 44 [51200/60000 (85%)]\tTrain Loss: 0.031222\n",
      "Train epoch: 44 [57600/60000 (96%)]\tTrain Loss: 0.000000\n",
      "Train epoch: 45 [0/60000 (0%)]\tTrain Loss: 0.000002\n",
      "Train epoch: 45 [6400/60000 (11%)]\tTrain Loss: 0.000006\n",
      "Train epoch: 45 [12800/60000 (21%)]\tTrain Loss: 0.000014\n",
      "Train epoch: 45 [19200/60000 (32%)]\tTrain Loss: 0.000017\n",
      "Train epoch: 45 [25600/60000 (43%)]\tTrain Loss: 0.000000\n",
      "Train epoch: 45 [32000/60000 (53%)]\tTrain Loss: 0.001807\n",
      "Train epoch: 45 [38400/60000 (64%)]\tTrain Loss: 0.037560\n",
      "Train epoch: 45 [44800/60000 (75%)]\tTrain Loss: 0.001659\n",
      "Train epoch: 45 [51200/60000 (85%)]\tTrain Loss: 0.000021\n",
      "Train epoch: 45 [57600/60000 (96%)]\tTrain Loss: 0.000004\n",
      "Train epoch: 46 [0/60000 (0%)]\tTrain Loss: 0.000006\n",
      "Train epoch: 46 [6400/60000 (11%)]\tTrain Loss: 0.000025\n",
      "Train epoch: 46 [12800/60000 (21%)]\tTrain Loss: 0.002911\n",
      "Train epoch: 46 [19200/60000 (32%)]\tTrain Loss: 0.000040\n",
      "Train epoch: 46 [25600/60000 (43%)]\tTrain Loss: 0.000001\n",
      "Train epoch: 46 [32000/60000 (53%)]\tTrain Loss: 0.000006\n",
      "Train epoch: 46 [38400/60000 (64%)]\tTrain Loss: 0.000099\n",
      "Train epoch: 46 [44800/60000 (75%)]\tTrain Loss: 0.000001\n",
      "Train epoch: 46 [51200/60000 (85%)]\tTrain Loss: 0.009993\n",
      "Train epoch: 46 [57600/60000 (96%)]\tTrain Loss: 0.003407\n",
      "Train epoch: 47 [0/60000 (0%)]\tTrain Loss: 0.000936\n",
      "Train epoch: 47 [6400/60000 (11%)]\tTrain Loss: 0.000113\n",
      "Train epoch: 47 [12800/60000 (21%)]\tTrain Loss: 0.000505\n",
      "Train epoch: 47 [19200/60000 (32%)]\tTrain Loss: 0.169200\n",
      "Train epoch: 47 [25600/60000 (43%)]\tTrain Loss: 0.000000\n",
      "Train epoch: 47 [32000/60000 (53%)]\tTrain Loss: 0.014701\n",
      "Train epoch: 47 [38400/60000 (64%)]\tTrain Loss: 0.000071\n",
      "Train epoch: 47 [44800/60000 (75%)]\tTrain Loss: 0.000406\n",
      "Train epoch: 47 [51200/60000 (85%)]\tTrain Loss: 0.000092\n",
      "Train epoch: 47 [57600/60000 (96%)]\tTrain Loss: 0.000001\n",
      "Train epoch: 48 [0/60000 (0%)]\tTrain Loss: 0.000719\n",
      "Train epoch: 48 [6400/60000 (11%)]\tTrain Loss: 0.000437\n",
      "Train epoch: 48 [12800/60000 (21%)]\tTrain Loss: 0.000182\n",
      "Train epoch: 48 [19200/60000 (32%)]\tTrain Loss: 0.000019\n",
      "Train epoch: 48 [25600/60000 (43%)]\tTrain Loss: 0.000349\n",
      "Train epoch: 48 [32000/60000 (53%)]\tTrain Loss: 0.001437\n",
      "Train epoch: 48 [38400/60000 (64%)]\tTrain Loss: 0.000019\n",
      "Train epoch: 48 [44800/60000 (75%)]\tTrain Loss: 0.000035\n",
      "Train epoch: 48 [51200/60000 (85%)]\tTrain Loss: 0.146379\n",
      "Train epoch: 48 [57600/60000 (96%)]\tTrain Loss: 0.019716\n",
      "Train epoch: 49 [0/60000 (0%)]\tTrain Loss: 0.000052\n",
      "Train epoch: 49 [6400/60000 (11%)]\tTrain Loss: 0.012446\n",
      "Train epoch: 49 [12800/60000 (21%)]\tTrain Loss: 0.000014\n",
      "Train epoch: 49 [19200/60000 (32%)]\tTrain Loss: 0.000000\n",
      "Train epoch: 49 [25600/60000 (43%)]\tTrain Loss: 0.000054\n",
      "Train epoch: 49 [32000/60000 (53%)]\tTrain Loss: 0.085724\n",
      "Train epoch: 49 [38400/60000 (64%)]\tTrain Loss: 0.000414\n",
      "Train epoch: 49 [44800/60000 (75%)]\tTrain Loss: 0.000026\n",
      "Train epoch: 49 [51200/60000 (85%)]\tTrain Loss: 0.000229\n",
      "Train epoch: 49 [57600/60000 (96%)]\tTrain Loss: 0.000007\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "best_val_loss = 999\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % display_step == 0:\n",
    "            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(epoch,  batch_idx * len(data),\n",
    "                                                                                 len(train_loader.dataset),\n",
    "                                                                                 100. * batch_idx / len(train_loader),\n",
    "                                                                                 loss.item()))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            output = F.log_softmax(output, dim = 1)\n",
    "            test_loss += criterion(output, target)\n",
    "            pred = output.argmax(dim = 1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        if test_loss < best_val_loss:\n",
    "            best_val_loss = test_loss\n",
    "            torch.save(model.state_dict(), checkpoint)\n",
    "            print(\"***********    TEST_ACC = {}%    ***********\".format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7725d12-5d63-4522-a353-538e1a1a4d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d4f73f3-6e88-4538-934a-3a61904e70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = iter(test_loader)\n",
    "data, target = next(item)\n",
    "test_idx = random.choice(range(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fbec3d2-4d71-41da-b5f3-f7c22334b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[test_idx]\n",
    "target = target[test_idx]\n",
    "assert data.shape == (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a4e18a5-5a13-4026-b9a6-75e9a496e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, model):\n",
    "    data = torch.unsqueeze(data, dim = 0)\n",
    "    data = data.to(device)\n",
    "    output = model(data)\n",
    "    output = F.log_softmax(output, dim = 1)\n",
    "    pred = output.argmax(dim = 1, keepdim = True)\n",
    "    print('Predict number : ', pred[0][0].detach().cpu().numpy())\n",
    "    plt.imshow(data[0][0].detach().cpu().numpy(), cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d5ecdb6-b954-444b-85d8-7c40ee762d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict number :  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.to(device)\n",
    "plot(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ad52b-1b04-425d-8237-cd9b255f8f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
