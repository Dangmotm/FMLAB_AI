{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9835f067-46d9-4993-98db-d56ba2f35d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 10 22:33:02 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.83                 Driver Version: 576.83         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A2000 Laptop GPU  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P0             12W /   45W |     655MiB /   4096MiB |     13%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           21208    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           22028    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           22804    C+G   ....0.3595.94\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           24004    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           27416    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d814c56-1a1f-4300-82d9-c45ff64cc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bn(bn1, bn2):\n",
    "    err = False\n",
    "\n",
    "    if not torch.allclose(bn1.running_mean, bn2.running_mean):\n",
    "        print('Diff in running mean: {} vs {}'.format(bn1.running_mean, bn2.running_mean))\n",
    "        err = True\n",
    "\n",
    "    if not torch.allclose(bn1.running_var, bn2.running_var):\n",
    "        print('Diff in running var: {} vs {]'.format(bn1.running_var, bn2.running_var))\n",
    "        err = True\n",
    "\n",
    "    if bn1.affine and bn2.affine:\n",
    "        \n",
    "        if not torch.allclose(bn1.weight, bn2.weight):\n",
    "            print('Diff in weight: {} vs {}'.format(bn1.weight, bn2.weight))\n",
    "            err = True\n",
    "\n",
    "        if not torch.allclose(bn1.bias, bn2.bias):\n",
    "            print('Diff in bias: {} vs {}'.format(bn1.bias, bn2.bias))\n",
    "            err = True\n",
    "\n",
    "    if not err:\n",
    "        print('All parameters are equal!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22acb178-8ac6-4311-8e1c-3d629d389623",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBatchNorm2d(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, eps = 1e-5, momentum = 0.1, affine = True, track_running_stats = True):\n",
    "        super(MyBatchNorm2d, self).__init__(num_features, eps, momentum,\n",
    "                                            affine, track_running_stats)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self._check_input_dim(input)\n",
    "\n",
    "        exponential_average_factor = 0.0\n",
    "\n",
    "        if self.training and self.track_running_stats:\n",
    "            if self.num_batches_tracked is not None:\n",
    "                self.num_batches_tracked += 1\n",
    "                if self.momentum is None:\n",
    "                    exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n",
    "                else:\n",
    "                    exponential_average_factor = self.momentum\n",
    "\n",
    "        if self.training:\n",
    "            mean = input.mean([0, 2, 3])\n",
    "            var = input.var([0, 2, 3], unbiased = False)\n",
    "            n = input.numel() / input.size(1)\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = exponential_average_factor * mean\\\n",
    "                    + (1 - exponential_average_factor) * self.running_mean\n",
    "                \n",
    "                self.running_var = exponential_average_factor * var * n / (n - 1)\\\n",
    "                    + (1 - exponential_average_factor) * self.running_var\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "\n",
    "        input = (input - mean[None, :, None, None]) / (torch.sqrt(var[None, :, None, None] + self.eps))\n",
    "        \n",
    "        if self.affine:\n",
    "            input = input * self.weight[None, :, None, None] + self.bias[None, :, None, None]\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30141a14-8707-494e-90ca-aadf4faafd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters are equal!\n",
      "All parameters are equal!\n"
     ]
    }
   ],
   "source": [
    "my_bn = MyBatchNorm2d(3, affine = True)\n",
    "bn = nn.BatchNorm2d(3, affine = True)\n",
    "\n",
    "compare_bn(my_bn, bn)\n",
    "my_bn.load_state_dict(bn.state_dict())\n",
    "compare_bn(my_bn, bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73044465-6ec5-4d9f-bbce-4e4e3189d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters are equal!\n",
      "Max Diff:  tensor(2.3842e-07, grad_fn=<MaxBackward1>)\n",
      "All parameters are equal!\n",
      "Max Diff:  tensor(7.1526e-07, grad_fn=<MaxBackward1>)\n",
      "All parameters are equal!\n",
      "Max Diff:  tensor(5.3644e-07, grad_fn=<MaxBackward1>)\n",
      "All parameters are equal!\n",
      "Max Diff:  tensor(3.4571e-06, grad_fn=<MaxBackward1>)\n",
      "All parameters are equal!\n",
      "Max Diff:  tensor(1.4901e-06, grad_fn=<MaxBackward1>)\n",
      "Diff in running mean: tensor([-0.0010, -0.0005, -0.0007]) vs tensor([-0.0010, -0.0005, -0.0007])\n",
      "Max Diff:  tensor(8.3447e-07, grad_fn=<MaxBackward1>)\n",
      "All parameters are equal!\n",
      "Max Diff:  tensor(1.0729e-06, grad_fn=<MaxBackward1>)\n",
      "All parameters are equal!\n",
      "Max Diff:  tensor(9.5367e-07, grad_fn=<MaxBackward1>)\n",
      "All parameters are equal!\n",
      "Max Diff:  tensor(2.3842e-07, grad_fn=<MaxBackward1>)\n",
      "All parameters are equal!\n",
      "Max Diff:  tensor(3.5763e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    scale = torch.randint(1, 10, (1,)).float()\n",
    "    bias = torch.randint(-10, 10, (1,)).float()\n",
    "    x = torch.rand(10, 3, 100, 100) * scale + bias\n",
    "    out1 = my_bn(x)\n",
    "    out2 = bn(x)\n",
    "    compare_bn(my_bn, bn)\n",
    "\n",
    "    torch.allclose(out1, out2)\n",
    "    print('Max Diff: ', (out1 - out2).abs().max())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e413ae6-f58e-4990-841a-a0b5173155b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters are equal!\n",
      "All parameters are equal!\n",
      "All parameters are equal!\n",
      "All parameters are equal!\n",
      "All parameters are equal!\n",
      "All parameters are equal!\n",
      "All parameters are equal!\n",
      "All parameters are equal!\n",
      "All parameters are equal!\n",
      "All parameters are equal!\n"
     ]
    }
   ],
   "source": [
    "my_bn.eval()\n",
    "bn.eval()\n",
    "\n",
    "for _ in range(10):\n",
    "    scale = torch.randint(1, 10, (1,)).float()\n",
    "    bias = torch.randint(-10, 10, (1,)).float()\n",
    "\n",
    "    x = torch.rand(10, 3, 100, 100) * scale + bias\n",
    "    out1 = my_bn(x)\n",
    "    out2 = bn(x)\n",
    "    compare_bn(my_bn, bn)\n",
    "\n",
    "    torch.allclose(out1, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a73a6f-3866-4972-b23d-1c1466c966e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir = \"./data\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root = data_dir, train = True, download = True, transform = transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root = data_dir, train = False, download = True, transform = transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11457f8d-a80f-4170-b003-cac522652308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, l1 = 120, l2 = 84):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.softmax(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "287315e9-c5a6-4c2c-9b29-39c95b459e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = load_data('./data')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 128, shuffle = True)\n",
    "\n",
    "epochs = 50\n",
    "warm_epoch = 5\n",
    "init_lr = 1e-1\n",
    "last_lr = 1e-5\n",
    "T_max = epochs\n",
    "T_cur = 0\n",
    "lr_list = [0]\n",
    "\n",
    "net = Net()\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = init_lr, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "144113b8-456f-4277-b96d-0b77d6b03969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\envs\\Dang\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1] loss: 2.301\n",
      "[Epoch  2] loss: 2.166\n",
      "[Epoch  3] loss: 2.083\n",
      "[Epoch  4] loss: 2.088\n",
      "[Epoch  5] loss: 2.279\n",
      "[Epoch  6] loss: 2.356\n",
      "[Epoch  7] loss: 2.361\n",
      "[Epoch  8] loss: 2.361\n",
      "[Epoch  9] loss: 2.361\n",
      "[Epoch  10] loss: 2.361\n",
      "[Epoch  11] loss: 2.361\n",
      "[Epoch  12] loss: 2.361\n",
      "[Epoch  13] loss: 2.361\n",
      "[Epoch  14] loss: 2.361\n",
      "[Epoch  15] loss: 2.361\n",
      "[Epoch  16] loss: 2.361\n",
      "[Epoch  17] loss: 2.361\n",
      "[Epoch  18] loss: 2.361\n",
      "[Epoch  19] loss: 2.361\n",
      "[Epoch  20] loss: 2.361\n",
      "[Epoch  21] loss: 2.361\n",
      "[Epoch  22] loss: 2.361\n",
      "[Epoch  23] loss: 2.361\n",
      "[Epoch  24] loss: 2.361\n",
      "[Epoch  25] loss: 2.361\n",
      "[Epoch  26] loss: 2.361\n",
      "[Epoch  27] loss: 2.361\n",
      "[Epoch  28] loss: 2.361\n",
      "[Epoch  29] loss: 2.361\n",
      "[Epoch  30] loss: 2.361\n",
      "[Epoch  31] loss: 2.361\n",
      "[Epoch  32] loss: 2.361\n",
      "[Epoch  33] loss: 2.361\n",
      "[Epoch  34] loss: 2.361\n",
      "[Epoch  35] loss: 2.361\n",
      "[Epoch  36] loss: 2.361\n",
      "[Epoch  37] loss: 2.361\n",
      "[Epoch  38] loss: 2.361\n",
      "[Epoch  39] loss: 2.361\n",
      "[Epoch  40] loss: 2.361\n",
      "[Epoch  41] loss: 2.361\n",
      "[Epoch  42] loss: 2.361\n",
      "[Epoch  43] loss: 2.361\n",
      "[Epoch  44] loss: 2.361\n",
      "[Epoch  45] loss: 2.361\n",
      "[Epoch  46] loss: 2.361\n",
      "[Epoch  47] loss: 2.361\n",
      "[Epoch  48] loss: 2.361\n",
      "[Epoch  49] loss: 2.361\n",
      "[Epoch  50] loss: 2.361\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    epoch_steps = 0\n",
    "    T_cur += 1\n",
    "\n",
    "    if epoch <= warm_epoch:\n",
    "        optimizer.param_groups[0]['lr'] = (1.0 * epoch) / warm_epoch * init_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = last_lr + (init_lr - last_lr) + (1 + np.cos(T_cur * np.pi / T_max)) / 2\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        epoch_steps += 1\n",
    "\n",
    "        if i + 1 == len(trainloader):\n",
    "            print(\"[Epoch % d] loss: %.3f\" % (epoch, running_loss / epoch_steps))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    lr_list.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341085a9-f5e9-4b16-bd97-2b80e24ccf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(list(range(len(lr_list))), lr_list, label = 'lr')\n",
    "plt.xlabel(\"Epoch\", fontsize = 14)\n",
    "plt.ylabel(\"Learning rate\", fontsize = 14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf9c214-d436-4de2-b28c-84fdc4b10388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ray.tune import CLIReporter\n",
    "from ray import tune\n",
    "from torch.utils.data import random_split\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2f3de10-0ca2-4792-97ca-f7fea255c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
    "    net = Net(config[\"l1\"], config[\"l2\"])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr = config[\"lr\"], momentum = 0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data(data_dir)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size = int(config[\"batch_size\"]),\n",
    "        shuffle = True,\n",
    "        num_workers = 0)\n",
    "    \n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size = int(config[\"batch_size\"]),\n",
    "        shuffle = True,\n",
    "        num_workers = 0)\n",
    "\n",
    "    for epoch in range(5):  \n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            \n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  \n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "            print(\"*\" * 10, path, \"*\" * 10)\n",
    "\n",
    "        tune.report(loss = (val_loss / val_steps), accuracy = correct / total)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89d9139a-55ca-463c-92eb-bf1afb97747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 23:07:32,655\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-12-10 23:07:33 (running for 00:00:00.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: C:/Users/DELL55~1/AppData/Local/Temp/ray/session_2025-12-10_22-45-43_547543_20124/artifacts/2025-12-10_23-07-32/train_cifar_2025-12-10_23-07-32/driver_artifacts\n",
      "Number of trials: 64/64 (64 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-12-10 23:07:38 (running for 00:00:05.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: C:/Users/DELL55~1/AppData/Local/Temp/ray/session_2025-12-10_22-45-43_547543_20124/artifacts/2025-12-10_23-07-32/train_cifar_2025-12-10_23-07-32/driver_artifacts\n",
      "Number of trials: 64/64 (64 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 23:07:41,700\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-12-10 23:07:41,741\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Dell 5520/ray_results/train_cifar_2025-12-10_23-07-32' in 0.0408s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-12-10 23:07:41 (running for 00:00:09.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: C:/Users/DELL55~1/AppData/Local/Temp/ray/session_2025-12-10_22-45-43_547543_20124/artifacts/2025-12-10_23-07-32/train_cifar_2025-12-10_23-07-32/driver_artifacts\n",
      "Number of trials: 64/64 (64 PENDING)\n",
      "+-------------------------+----------+-------+--------------+------+------+--------+\n",
      "| Trial name              | status   | loc   |   batch_size |   l1 |   l2 |     lr |\n",
      "|-------------------------+----------+-------+--------------+------+------+--------|\n",
      "| train_cifar_55c32_00000 | PENDING  |       |           16 |   32 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00001 | PENDING  |       |           16 |   64 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00002 | PENDING  |       |           16 |   32 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00003 | PENDING  |       |           16 |   64 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00004 | PENDING  |       |           16 |   32 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00005 | PENDING  |       |           16 |   64 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00006 | PENDING  |       |           16 |   32 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00007 | PENDING  |       |           16 |   64 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00008 | PENDING  |       |           16 |   32 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00009 | PENDING  |       |           16 |   64 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00010 | PENDING  |       |           16 |   32 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00011 | PENDING  |       |           16 |   64 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00012 | PENDING  |       |           16 |   32 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00013 | PENDING  |       |           16 |   64 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00014 | PENDING  |       |           16 |   32 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00015 | PENDING  |       |           16 |   64 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00016 | PENDING  |       |           16 |   32 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00017 | PENDING  |       |           16 |   64 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00018 | PENDING  |       |           16 |   32 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00019 | PENDING  |       |           16 |   64 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00020 | PENDING  |       |           16 |   32 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00021 | PENDING  |       |           16 |   64 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00022 | PENDING  |       |           16 |   32 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00023 | PENDING  |       |           16 |   64 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00024 | PENDING  |       |           16 |   32 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00025 | PENDING  |       |           16 |   64 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00026 | PENDING  |       |           16 |   32 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00027 | PENDING  |       |           16 |   64 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00028 | PENDING  |       |           16 |   32 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00029 | PENDING  |       |           16 |   64 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00030 | PENDING  |       |           16 |   32 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00031 | PENDING  |       |           16 |   64 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00032 | PENDING  |       |           16 |   32 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00033 | PENDING  |       |           16 |   64 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00034 | PENDING  |       |           16 |   32 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00035 | PENDING  |       |           16 |   64 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00036 | PENDING  |       |           16 |   32 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00037 | PENDING  |       |           16 |   64 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00038 | PENDING  |       |           16 |   32 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00039 | PENDING  |       |           16 |   64 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00040 | PENDING  |       |           16 |   32 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00041 | PENDING  |       |           16 |   64 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00042 | PENDING  |       |           16 |   32 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00043 | PENDING  |       |           16 |   64 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00044 | PENDING  |       |           16 |   32 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00045 | PENDING  |       |           16 |   64 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00046 | PENDING  |       |           16 |   32 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00047 | PENDING  |       |           16 |   64 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00048 | PENDING  |       |           16 |   32 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00049 | PENDING  |       |           16 |   64 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00050 | PENDING  |       |           16 |   32 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00051 | PENDING  |       |           16 |   64 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00052 | PENDING  |       |           16 |   32 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00053 | PENDING  |       |           16 |   64 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00054 | PENDING  |       |           16 |   32 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00055 | PENDING  |       |           16 |   64 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00056 | PENDING  |       |           16 |   32 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00057 | PENDING  |       |           16 |   64 |   16 | 0.0001 |\n",
      "| train_cifar_55c32_00058 | PENDING  |       |           16 |   32 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00059 | PENDING  |       |           16 |   64 |   32 | 0.0001 |\n",
      "| train_cifar_55c32_00060 | PENDING  |       |           16 |   32 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00061 | PENDING  |       |           16 |   64 |   16 | 0.01   |\n",
      "| train_cifar_55c32_00062 | PENDING  |       |           16 |   32 |   32 | 0.01   |\n",
      "| train_cifar_55c32_00063 | PENDING  |       |           16 |   64 |   32 | 0.01   |\n",
      "+-------------------------+----------+-------+--------------+------+------+--------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     12\u001b[39m     reporter = CLIReporter(metric_columns=[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtraining_iteration\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     14\u001b[39m     result = tune.run(\n\u001b[32m     15\u001b[39m         partial(train_cifar, data_dir=data_dir),\n\u001b[32m     16\u001b[39m         resources_per_trial = {\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m\"\u001b[39m: gpus_per_trial},\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m         progress_reporter = reporter\n\u001b[32m     20\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(num_samples, gpus_per_trial)\u001b[39m\n\u001b[32m      5\u001b[39m config = {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33ml1\u001b[39m\u001b[33m\"\u001b[39m: tune.grid_search([\u001b[32m32\u001b[39m, \u001b[32m64\u001b[39m]),\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m\"\u001b[39m: tune.grid_search([\u001b[32m16\u001b[39m, \u001b[32m32\u001b[39m]),\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: tune.grid_search([\u001b[32m1e-4\u001b[39m, \u001b[32m1e-2\u001b[39m]),\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: tune.grid_search([\u001b[32m16\u001b[39m])\n\u001b[32m     10\u001b[39m }\n\u001b[32m     12\u001b[39m reporter = CLIReporter(metric_columns=[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtraining_iteration\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m result = \u001b[43mtune\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_cifar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_reporter\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporter\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\tune\\tune.py:1026\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[39m\n\u001b[32m   1022\u001b[39m     _report_air_progress(runner, air_progress_reporter, force=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1024\u001b[39m all_trials = runner.get_trials()\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m incomplete_trials = []\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m all_trials:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1978\u001b[39m, in \u001b[36mTuneController.cleanup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1976\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1977\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1978\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cleanup_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1979\u001b[39m     \u001b[38;5;28mself\u001b[39m.end_experiment_callbacks()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:792\u001b[39m, in \u001b[36mTuneController._cleanup_trials\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m     trial = \u001b[38;5;28mself\u001b[39m._actor_to_trial[tracked_actor]\n\u001b[32m    788\u001b[39m     logger.debug(\n\u001b[32m    789\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScheduling trial stop at end of experiment (trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    790\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtracked_actor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    791\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_schedule_trial_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;66;03m# Clean up cached actors now\u001b[39;00m\n\u001b[32m    795\u001b[39m \u001b[38;5;28mself\u001b[39m._cleanup_cached_actors(force_all=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1403\u001b[39m, in \u001b[36mTuneController._schedule_trial_stop\u001b[39m\u001b[34m(self, trial, exception)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28mself\u001b[39m._actor_to_trial.pop(tracked_actor)\n\u001b[32m   1401\u001b[39m trial.set_ray_actor(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_remove_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:816\u001b[39m, in \u001b[36mTuneController._remove_actor\u001b[39m\u001b[34m(self, tracked_actor)\u001b[39m\n\u001b[32m    811\u001b[39m stop_future = \u001b[38;5;28mself\u001b[39m._actor_manager.schedule_actor_task(\n\u001b[32m    812\u001b[39m     tracked_actor, \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m, _return_future=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    813\u001b[39m )\n\u001b[32m    814\u001b[39m now = time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_actor_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkill\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_future\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop_future\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    819\u001b[39m     \u001b[38;5;66;03m# If the actor was previously alive, track\u001b[39;00m\n\u001b[32m    820\u001b[39m     \u001b[38;5;28mself\u001b[39m._stopping_actors[tracked_actor] = now\n\u001b[32m    821\u001b[39m     \u001b[38;5;28mself\u001b[39m._earliest_stopping_actor = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m._earliest_stopping_actor, now)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\air\\execution\\_internal\\actor_manager.py:637\u001b[39m, in \u001b[36mRayActorManager.remove_actor\u001b[39m\u001b[34m(self, tracked_actor, kill, stop_future)\u001b[39m\n\u001b[32m    633\u001b[39m     _, _, resource_request = \u001b[38;5;28mself\u001b[39m._pending_actors_to_attrs.pop(tracked_actor)\n\u001b[32m    634\u001b[39m     \u001b[38;5;28mself\u001b[39m._resource_request_to_pending_actors[resource_request].remove(\n\u001b[32m    635\u001b[39m         tracked_actor\n\u001b[32m    636\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resource_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcancel_resource_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresource_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresource_request\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\air\\execution\\resources\\placement_group.py:168\u001b[39m, in \u001b[36mPlacementGroupResourceManager.cancel_resource_request\u001b[39m\u001b[34m(self, resource_request)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    162\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot cancel resource request: No placement group was \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstaged or is ready. Make sure to not cancel more resource \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrequests than you\u001b[39m\u001b[33m'\u001b[39m\u001b[33mve created. Request: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_request\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    165\u001b[39m         )\n\u001b[32m    167\u001b[39m \u001b[38;5;28mself\u001b[39m._pg_to_request.pop(pg)\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_placement_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py:142\u001b[39m, in \u001b[36mclient_mode_wrap.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m     ref = f.remote(*args, **kwargs)\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ray.get(ref)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\ray\\util\\placement_group.py:232\u001b[39m, in \u001b[36mremove_placement_group\u001b[39m\u001b[34m(placement_group)\u001b[39m\n\u001b[32m    229\u001b[39m worker = ray._private.worker.global_worker\n\u001b[32m    230\u001b[39m worker.check_connected()\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_placement_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplacement_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3413\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3409\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3411\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3413\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3414\u001b[39m     )\n\u001b[32m   3416\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3467\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3464\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3465\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3466\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3467\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3469\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3470\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3471\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3472\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\ultratb.py:1188\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1187\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\ultratb.py:1059\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1056\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1058\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1059\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1063\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1065\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1066\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1074\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1075\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\ultratb.py:867\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    860\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    865\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    866\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    871\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    872\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\ultratb.py:779\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    769\u001b[39m         frames.append(\n\u001b[32m    770\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    771\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    776\u001b[39m             )\n\u001b[32m    777\u001b[39m         )\n\u001b[32m    778\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    781\u001b[39m     frames.append(\n\u001b[32m    782\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    783\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\ultratb.py:654\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    651\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    653\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     \u001b[43m_format_traceback_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheme_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theme_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlvals_toks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m )\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\IPython\\core\\tbtools.py:99\u001b[39m, in \u001b[36m_format_traceback_lines\u001b[39m\u001b[34m(lines, theme, has_colors, lvals_toks)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     98\u001b[39m lineno = stack_line.lineno\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m line = \u001b[43mstack_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygmented\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m)\u001b[49m.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack_line.is_current:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# This is the line with the error\u001b[39;00m\n\u001b[32m    102\u001b[39m     pad = numbers_width - \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(lineno))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\stack_data\\core.py:391\u001b[39m, in \u001b[36mLine.render\u001b[39m\u001b[34m(self, markers, strip_leading_indent, pygmented, escape_html)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pygmented \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frame_info.scope:\n\u001b[32m    390\u001b[39m     assert_(\u001b[38;5;129;01mnot\u001b[39;00m markers, \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot use pygmented with markers\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     start_line, lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pygmented_scope_lines\u001b[49m\n\u001b[32m    392\u001b[39m     result = lines[\u001b[38;5;28mself\u001b[39m.lineno - start_line]\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strip_leading_indent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\stack_data\\utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\stack_data\\core.py:824\u001b[39m, in \u001b[36mFrameInfo._pygmented_scope_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     ranges = []\n\u001b[32m    823\u001b[39m code = atext.get_text(scope)\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m lines = \u001b[43m_pygmented_with_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m start_line = \u001b[38;5;28mself\u001b[39m.source.line_range(scope)[\u001b[32m0\u001b[39m]\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_line, lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\stack_data\\utils.py:164\u001b[39m, in \u001b[36m_pygmented_with_ranges\u001b[39m\u001b[34m(formatter, code, ranges)\u001b[39m\n\u001b[32m    161\u001b[39m             length += \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[32m    162\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m ttype, value\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m lexer = \u001b[43mMyLexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstripnl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    166\u001b[39m     highlighted = pygments.highlight(code, lexer, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\pygments\\lexer.py:660\u001b[39m, in \u001b[36mRegexLexerMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwds)\u001b[39m\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m         \u001b[38;5;28mcls\u001b[39m._tokens = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_tokendef\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_tokendefs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m.\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\pygments\\lexer.py:599\u001b[39m, in \u001b[36mRegexLexerMeta.process_tokendef\u001b[39m\u001b[34m(cls, name, tokendefs)\u001b[39m\n\u001b[32m    597\u001b[39m tokendefs = tokendefs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.tokens[name]\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tokendefs):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokendefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\pygments\\lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\pygments\\lexer.py:588\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    586\u001b[39m         new_state = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    587\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m         new_state = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_new_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m                                           \u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m     tokens.append((rex, token, new_state))\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\pygments\\lexer.py:537\u001b[39m, in \u001b[36mRegexLexerMeta._process_new_state\u001b[39m\u001b[34m(cls, new_state, unprocessed, processed)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m istate \u001b[38;5;129;01min\u001b[39;00m new_state:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m istate != new_state, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcircular state ref \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mistate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m     itokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mistate\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    539\u001b[39m processed[tmp_state] = itokens\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (tmp_state,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\pygments\\lexer.py:579\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tdef) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwrong rule def \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     rex = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33muncompilable regex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m in state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\site-packages\\pygments\\lexer.py:508\u001b[39m, in \u001b[36mRegexLexerMeta._process_regex\u001b[39m\u001b[34m(cls, regex, rflags, state)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(regex, Future):\n\u001b[32m    507\u001b[39m     regex = regex.get()\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrflags\u001b[49m\u001b[43m)\u001b[49m.match\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\envs\\Dang\\Lib\\re\\__init__.py:225\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(pattern, flags)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return an iterator over all non-overlapping matches in the\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03m    string.  For each match, the iterator returns a Match object.\u001b[39;00m\n\u001b[32m    221\u001b[39m \n\u001b[32m    222\u001b[39m \u001b[33;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags).finditer(string)\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile\u001b[39m(pattern, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    226\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main(num_samples = 8, gpus_per_trial = 2):\n",
    "    \n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    \n",
    "    config = {\n",
    "        \"l1\": tune.grid_search([32, 64]),\n",
    "        \"l2\": tune.grid_search([16, 32]),\n",
    "        \"lr\": tune.grid_search([1e-4, 1e-2]),\n",
    "        \"batch_size\": tune.grid_search([16])\n",
    "    }\n",
    "    \n",
    "    reporter = CLIReporter(metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    \n",
    "    result = tune.run(\n",
    "        partial(train_cifar, data_dir=data_dir),\n",
    "        resources_per_trial = {\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config = config,\n",
    "        num_samples = num_samples,\n",
    "        progress_reporter = reporter\n",
    "    )\n",
    "\n",
    "main(num_samples = 8, gpus_per_trial = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3db44223-57e6-4d95-90fd-7c2eb5956749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f516d5c-2118-479b-8543-030653337def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.3318\u001b[0m       \u001b[32m0.1015\u001b[0m        \u001b[35m2.3044\u001b[0m  3.1464\n",
      "      2        \u001b[36m2.2926\u001b[0m       \u001b[32m0.1765\u001b[0m        \u001b[35m2.2561\u001b[0m  2.8745\n",
      "      3        \u001b[36m2.1945\u001b[0m       \u001b[32m0.2008\u001b[0m        \u001b[35m2.1252\u001b[0m  2.8929\n",
      "      4        \u001b[36m2.0703\u001b[0m       \u001b[32m0.2483\u001b[0m        \u001b[35m2.0221\u001b[0m  3.0015\n",
      "      5        \u001b[36m1.9685\u001b[0m       \u001b[32m0.2734\u001b[0m        \u001b[35m2.0017\u001b[0m  3.2073\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = load_data('./data')\n",
    "(X, y) = np.asarray(trainset.data[:]), np.asarray(trainset.targets[:])\n",
    "\n",
    "X = X.reshape((-1, 3, 32, 32))\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    Net,\n",
    "    max_epochs = 5,\n",
    "    lr = 0.01,\n",
    "    iterator_train__shuffle = True,\n",
    ")\n",
    "\n",
    "net.fit(X, y)\n",
    "y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7df2884-147d-4983-841c-6e226f5a1026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=16; total time=  10.9s\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=16; total time=  10.4s\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=16; total time=  11.9s\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=32; total time=  11.9s\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=32; total time=  13.3s\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=32; total time=  12.1s\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=64; total time=  11.9s\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=64; total time=  12.0s\n",
      "[CV] END ............lr=0.0001, module__l1=32, module__l2=64; total time=  12.5s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=16; total time=  13.1s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=16; total time=  12.8s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=16; total time=  13.4s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=32; total time=  13.9s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=32; total time=  14.4s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=32; total time=  13.4s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=64; total time=  13.3s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=64; total time=  12.8s\n",
      "[CV] END ............lr=0.0001, module__l1=64, module__l2=64; total time=  11.9s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=16; total time=  12.1s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=16; total time=  12.9s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=16; total time=  12.6s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=32; total time=  12.1s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=32; total time=  12.1s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=32; total time=  12.2s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=64; total time=  13.0s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=64; total time=  12.4s\n",
      "[CV] END ...........lr=0.0001, module__l1=128, module__l2=64; total time=  12.1s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=16; total time=  11.6s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=16; total time=  11.6s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=16; total time=  11.9s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=32; total time=  12.8s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=32; total time=  13.1s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=32; total time=  14.4s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=64; total time=  13.1s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=64; total time=  12.7s\n",
      "[CV] END .............lr=0.001, module__l1=32, module__l2=64; total time=  12.5s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=16; total time=  12.7s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=16; total time=  12.7s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=16; total time=  12.5s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=32; total time=  12.7s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=32; total time=  12.8s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=32; total time=  12.5s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=64; total time=  12.9s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=64; total time=  13.0s\n",
      "[CV] END .............lr=0.001, module__l1=64, module__l2=64; total time=  14.4s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=16; total time=  13.7s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=16; total time=  13.4s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=16; total time=  14.1s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=32; total time=  13.4s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=32; total time=  14.2s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=32; total time=  13.7s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=64; total time=  14.3s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=64; total time=  13.5s\n",
      "[CV] END ............lr=0.001, module__l1=128, module__l2=64; total time=  13.8s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=16; total time=  12.7s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=16; total time=  12.7s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=16; total time=  13.1s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=32; total time=  13.0s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=32; total time=  12.6s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=32; total time=  13.1s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=64; total time=  12.5s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=64; total time=  12.4s\n",
      "[CV] END ..............lr=0.01, module__l1=32, module__l2=64; total time=  12.4s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=16; total time=  12.5s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=16; total time=  12.8s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=16; total time=  13.5s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=32; total time=  13.4s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=32; total time=  13.5s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=32; total time=  13.6s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=64; total time=  13.5s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=64; total time=  14.3s\n",
      "[CV] END ..............lr=0.01, module__l1=64, module__l2=64; total time=  13.0s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=16; total time=  13.5s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=16; total time=  13.3s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=16; total time=  12.8s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=32; total time=  12.8s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=32; total time=  13.5s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=32; total time=  12.7s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=64; total time=  13.5s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=64; total time=  13.4s\n",
      "[CV] END .............lr=0.01, module__l1=128, module__l2=64; total time=  12.6s\n",
      "best score: 0.300, best params: {'lr': 0.01, 'module__l1': 64, 'module__l2': 32}\n"
     ]
    }
   ],
   "source": [
    "net.set_params(train_split = False, verbose = 0)\n",
    "\n",
    "params = {\n",
    "    'lr': [1e-4, 1e-3, 1e-2],\n",
    "    'module__l1': [32, 64, 128],\n",
    "    'module__l2': [16, 32, 64],\n",
    "}\n",
    "      \n",
    "gs = GridSearchCV(net, params, cv = 3, scoring = 'accuracy', verbose = 2)\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(\"best score: {:.3f}, best params: {}\".format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39e691-61d9-467f-a07f-89164da26c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
